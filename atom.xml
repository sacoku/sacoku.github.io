<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>sacoku&#39;s github.io</title>
  
  <subtitle>Develop History</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://sacoku.github.io/"/>
  <updated>2018-07-13T08:30:08.794Z</updated>
  <id>https://sacoku.github.io/</id>
  
  <author>
    <name>sacoku</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Iptables 일반사항</title>
    <link href="https://sacoku.github.io/2018/07/13/how-to-iptables/"/>
    <id>https://sacoku.github.io/2018/07/13/how-to-iptables/</id>
    <published>2018-07-13T08:00:11.000Z</published>
    <updated>2018-07-13T08:30:08.794Z</updated>
    
    <content type="html"><![CDATA[<h2 id="netfilter란"><a href="#netfilter란" class="headerlink" title="netfilter란?"></a>netfilter란?</h2><p>커널에서 패킷을 필터링 하는 모듈. iptables 가 netfilter 커널 모듈을 이용하여 패킷을 필터링 한다. 즉, iptables를 이용하여 패킷 룰-셋을 구축하며 netfilter가 룰셋에 따라서 패킷을 필터링 등의 역활을 수행한다.</p><h2 id="iptables란"><a href="#iptables란" class="headerlink" title="iptables란"></a>iptables란</h2><ul><li>iptables에는 세가지 chain이 있고 모든 패킷은 이 세가지 chain중 하나를 통과하게 된다. 이 세가지 chain은 <code>INPUT, OUTPUT, FORWARD chain</code>인데 우선 여러분의 컴퓨터로 들어가는 모든 패킷은 <code>INPUT chain</code>을 통과한다. 그리고 여러분의 컴퓨터에서 나가는 모든 패킷은 <code>OUTPUT chain</code>을 통과한다. 그리고 하나의 네트워크에서 다른 곳으로 보내는 모든 패킷은 <code>FORWARD chain</code> 을 통과한다.</li><li><p>iptables가 작동하는 방식은 이들 각각의 <code>INPUT, OUTPUT, FORWARD chain</code>에 당신이 어떠한 rule을 세우는 지에 따라 달라진다. 예를 들어 당신이 HTML 페이지를 요청하기 위해 <a href="http://www.yahoo.com에" target="_blank" rel="noopener">http://www.yahoo.com에</a> 패킷을 보낸다면 이 패킷은 우선 당신 컴퓨터의 <code>OUTPUT chain</code>을 통과하게 된다. 그러면 kernel에서 <code>OUTPUT chain</code>의 rule을 확인하고 rule과 match가 되는지 확인을 하게 된다. rule중에서 최초로 match되는 것에 의해 당신이 보낸 패킷의 운명이 결정되는 것이다. 만약 어떤 rule과도 match되지 않는다면 전체 chain의 정책이 ACCEPT냐 DROP이냐에 따라 패킷의 운명이 결정될 것이다. 그러고 나서 Yahoo! 에서 응답하는 패킷은 당신의 <code>INPUT chain</code>을 통과하게 될 것이다</p></li><li><p>iptables로 할 수 있는 일에는 몇가지 다른 것이 있다. 첫번째 작동은 전체 체인을 조절한다. 처음 시작은 세개의 미리 만들어진 체인으로 시작하는 데 이것은 제거될 수 없다 </p></li><li>iptables는 모듈로 되어있을 것이다. 이것은 <code>iptable_filter.o</code> 이다. 이것은 처음으로 iptables를 실행 할 때 자동으로 로드 될 것이다. 이것은 커널에 영구히 포함될 수도 있다</li><li>iptables 명령이 실행되기 전에는 기본적으로 만들어져 있는 체인 <code>INPUT, FORWARDING, OUTPUT chain</code>에는 아무런 규칙도 없다. </li></ul><h3 id="기본-Chain"><a href="#기본-Chain" class="headerlink" title="기본 Chain"></a>기본 Chain</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&amp;nbsp------&gt;INPUT------&gt; Linux Box ------&gt;OUTPUT---------&gt;</span><br><span class="line"></span><br><span class="line">---------↕-----------------------------↕</span><br><span class="line"></span><br><span class="line">---------└---------- FORWARD ----------┘</span><br></pre></td></tr></table></figure><p>Linux box를 도착지로 삼는 모든 패킷은 <code>INPUT Chain</code>을 통과하게 되며 Linux box에서 생성되 외부로 보내지는 모든 패킷은 <code>OUTPUT Chain</code>을 통과하게 된다. <code>Forward chain</code>은 엄밀히 말하자면 도착지가 Linux box가 아닌 패킷이 통과하게 되는 체인이다</p><h3 id="Chain의-실행-순서와-사용자-Chain과의-관계"><a href="#Chain의-실행-순서와-사용자-Chain과의-관계" class="headerlink" title="Chain의 실행 순서와 사용자 Chain과의 관계"></a>Chain의 실행 순서와 사용자 Chain과의 관계</h3><p>iptables의 강력한 기능중의 하나는 사용자가 기존의 세개의 체인 <code>INPUT, OUTPUT, FORWARD chain</code>외에 새로운 체인을 생성할 수 있다는 것이다.</p><p>타겟이 사용자 지정의 체인인 규칙에 패킷이 맞으면 패킷은 사용자 지정의 체인을 따라 움직이게 된다. 그 체인이 패킷의 운명을 결정하지 못하면 그리고 그 체인에 따른 이송이 끝나면, 패킷은 현제 체인의 다음 규칙으로 돌아온다 </p><p>이해를 위해 예를 들자면 아래의 그림은 두개의 체인이 있고 그것이 <code>INPUT</code> 과  <code>test</code> 라는 사용자 지정의 체인이 라고 가정해 보자</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">         `INPUT&apos;                         `test&apos; </span><br><span class="line">----------------------------    ----------------------------</span><br><span class="line">|  Rule1: -p ICMP -j DROP  |    |  Rule1: -s 192.168.1.1   |</span><br><span class="line">|--------------------------|    |--------------------------|</span><br><span class="line">|  Rule2: -p TCP -j test   |    |  Rule2: -d 192.168.1.1   |</span><br><span class="line">|--------------------------|    |--------------------------| </span><br><span class="line">|  Rule3: -p UDP -j DROP   |</span><br><span class="line">|--------------------------|</span><br></pre></td></tr></table></figure><p>192.168.1.1 로부터 와서 1.2.3.4 로 향하는 TCP 패킷이 있다고 가정해보자. 이것은 입력 체인으로 들어온다.</p><ol><li>Rule1 을 검사한다. =&gt; 맞지 않음</li><li>Rule2 맞음. 타겟은 “test”, 고로 다음 검사할 규칙은 “test” 의 시작이다</li><li>test의 Rule1 이 맞다. 그러나 이것이 타겟을 지정하지 않는다. 그러므로 다음 규칙이 검사된다</li><li>Rule 2. 맞지 않음.</li><li>체인의 끝에 도달.</li><li>다시 입력 체인으로 돌아가서 Rule3 을 검사 한다. 그것도 맞지 않음</li><li>그러므로 Drop 시켜 버림</li></ol><p>패킷의 이동경로를 그림으로 나타내보자</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">                              v    __________________________</span><br><span class="line"> `INPUT&apos;                |   /    `test&apos;                v</span><br><span class="line">------------------------|--/    -----------------------|----</span><br><span class="line">| Rule1                 | /|    | Rule1                |   |</span><br><span class="line">|-----------------------|/-|    |----------------------|---|</span><br><span class="line">| Rule2                 /  |    | Rule2                |   |</span><br><span class="line">|--------------------------|    -----------------------v----</span><br><span class="line">| Rule3                 /--+___________________________/</span><br><span class="line">------------------------|---</span><br><span class="line">                           v</span><br></pre></td></tr></table></figure><p>사용자 지정의 체인에서 대를 사용자 지정의 체인으로 갈수 있다. (그러나 루프를 돌 수는 없다. 루프를 발견하게 되면 패킷은 DROP  된다.</p><h3 id="Rule의-순서"><a href="#Rule의-순서" class="headerlink" title="Rule의 순서"></a>Rule의 순서</h3><p>iptables의 chain에서는 먼저 등록 된 rule이 효력을 발생하기때문에 등록을 하는 순서가 중요하다. 모든 것을 거부하는 설정이 먼저 오게 되면 그 이후에 포트를 열어주는 설정이 와도 효과가 없다. 그러므로 허용하는 정책이 먼저 오고 나서 거부하는 정책이 와야  한다.</p><p>-A 옵션을 줌으로써 우리는 새로운 규칙을 chain의 맨 아래에 추가하게 된다. 즉 chain상의 상위 rule이 먼저 작동하기 때문에, 만일 새로 추가하는 rule을 먼저 작동시키기 위해서는 -I 옵션을 줌으로써 새로운 rule을 원하는 위치에 놓을 수 있다. 예를 들어 INPUT chain의 가장 위에 어떤 rule을 놓고 싶다면 “-I INPUT 1” 이라 명령하면 된다. 그리고 다른 위치로 놓고 싶다면 1을 다른 숫자로 바꿔주면  된다.</p><p>이미 위치된 rule을 다른 위치로 바꾸고 싶다면 -R 옵션을 주면 된다. -I 옵션을 주는 것과 마찬가지로 사용할 수 있는데 다만 -I옵션을 사용해서 1의 위치에 놓으면 다른 rule들이 밑으로 한 칸씩 내려가는 반면 -R옵션을 사용해서 1의 위치에 놓으면 그 위치의 rule은  삭제된다.</p><p>rule을 삭제하고 싶다면 -D옵션과 숫자를 사용하면 되고, -L 옵션을 사용하면 작성된 모든 rule의 목록을 보여주고, -F 옵션을 주면 해당 chain의 모든 rule을 삭제한다. 그리고 만약 chain을 명시하지 않았다면 모든 것을 flush할 것이다.</p><h2 id="iptables-예제"><a href="#iptables-예제" class="headerlink" title="iptables 예제"></a>iptables 예제</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -s 200.200.200.1 -j DROP</span><br></pre></td></tr></table></figure><blockquote><p>200.200.200.1 이라는 source IP(-s)로부터 오는(INPUT) 모든 패킷을 막는(DROP) 규칙을 추가(A)한다.    -&gt; 이 한 줄의 명령으로 200.200.200.1로부터 오는 모든 패킷을 무시할 수 있다. 옵션의 순서는 바뀌어도 상관이 없다. 즉 -j DROP이 -s 200.200.200.1 보다 앞에 가도 상관이 없다. 만약 그 반대로 200.200.200.1로 패킷이 못가도록 하려면 INPUT 대신에 OUTPUT을, -s 대신에 -d(destination) 옵션을 주면된다</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -p tcp --sport 25 -j ACCEPT</span><br></pre></td></tr></table></figure><blockquote><p>25번이라는 source포트(–sport)에서 오는(INPUT) protocol이(-p) tcp인 모든 접속을 허락하는(ACCEPT) 규칙을 추가(A)한다.    -&gt; source port 와 destination port를 혼동하면 안된다. 즉 클라이언트는 어떤 포트로도 작동할 수 있는 반면에 서버는 23번 포트로 작동하기 때문이다. 즉 특정 서비스를 차단하기 위해서는 -destination-port를 이용하면 되고, 그 반대는 -source-port를 이용하면 된다.     -&gt; IP의 영역을 선택하고 싶다면 200.200.200.0/24 와 같이 설정하면 된다. 이것은 200.200.200.* 에 해당하는 모든 IP를 선택하는 것과 같다 </p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -s 200.200.200.1 -p tcp --destination-port telnet -j DROP</span><br></pre></td></tr></table></figure><blockquote><p>200.200.200.1 이라는 source IP(-s)로부터 오는(INPUT) protocol이(-p) tcp이고 목적지 port(–destination-port)가 telnet인 패킷의 접속을 막는(DROP) 규칙을 추가(A)한다</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -i eth1 -s 192.168.1.0/24 -d 0/0 -j ACCEPT</span><br></pre></td></tr></table></figure><blockquote><p>192.168.1.0/24라는 source IP(-s)로부터 오는(INPUT) 서버안으로 들어오는 인터페이스(-i)가 eth1이고 destination IP(-d)가 어떤 IP라도(0/0) 접속을 허락하는(ACCEPT) 규칙을 추가(A)한다. (서버자체에 대한 접속이 아니라 마스커레이딩등을 이용하여 랜카드 두 개를 장착한 경우 eth1에 연결된 내부 PC에서 외부로의 접속 허용)</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -p tcp --destination-port telnet -i ppp0 -j DROP</span><br></pre></td></tr></table></figure><blockquote><p>protocol이(-p) tcp이고 목적지 port(–destination-port)가 telnet이며, 서버안으로 들어오는 인터페이스(-i)가 ppp0인 패킷의 접속을 막는(DROP) 규칙을 추가(A)한다. 이렇게 함으로써 우리는 LAN상의 사용자는 telnet을 사용하고 그밖에 Internet상의 사용자는 telnet 을 사용하지 못하도록 할 수 있다</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -i ppp0 -p tcp --syn -j DROP</span><br></pre></td></tr></table></figure><blockquote><p>ppp0 로 들어오는 모든 tcp의 연결을 무시해버림. 두 컴퓨터가 TCP connection으로 패킷을 주고 받는다면 그 connection은 우선 초기화가 되어야 한다. 이것은 바로 SYN packet이 담당한다. SYN packet은 단순히 다른 컴퓨터에게 주고 받을 준비가 되었다는 것만 알려주는 초기화 기능만을 한다. 이제 서비스를 요청하는 컴퓨터는 우선적으로 SYN packet을 보낸다는 것을 알게 되었다. 그러므로 들어오는 SYN packet만 막기만 하면 다른 컴퓨터가 당신 컴퓨터의 서비스를 이용하지 못하게 할 수 있고, 하지만 당신은 그들과 통신할 수 있는 것이다. 즉 이와 같이 하면 당신이 먼저 패킷을 보내서 요청이 들어오는 것이 아니면 모두 무시해 버리게 된다</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -i ppp0 -p tcp --syn --destination-port ! 80 -j DROP</span><br></pre></td></tr></table></figure><p>80번 포트만 제외하고 모든 SYN packet들을 막는다. 만약 당신이 웹서비스를 위해 하나의 포트(예를들어 80번-HTTP)만 열어두고 싶다면 역시 한가지 방법이 있다. 바로 “!” 마크를 사용하면 되는데 많은 프로그래밍 언어에서처럼 “!”은 “not”을 의미한다. 예를들어 80번 포트만 제외하고 모든 SYN packet들을 막고싶다면 위와 같이하면된다</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -p icmp --icmp-type <span class="built_in">echo</span>-request -j REJECT  </span><br><span class="line">$ iptables -A INPUT -p icmp --icmp-type 8 -j REJECT</span><br></pre></td></tr></table></figure><blockquote><p>protocol이(-p) icmp이고 icmp 의 type이 echo-request인 패킷이 오는(INPUT) 것을 거절하는(REJECT) 규칙을 추가(A)한다.  (외부에서의 ping을 거절하는 방법임 / echo-request대신에 8을 해도 됨 )</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -p tcp --dport 20:30 -j DROP</span><br></pre></td></tr></table></figure><blockquote><p>protocol이(-p) tcp이고 목적지 port(–dport)가 20번부터 30번까지인 패킷이 오는(INPUT) 것을 막는(DROP) 규칙을 추가(A)한다. </p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -m state --state INVALID -j DROP</span><br></pre></td></tr></table></figure><blockquote><p>network상태가(state –state)가 INVALID인 패킷이 오는(INPUT) 것을 막는(DROP) 규칙을 추가(A)한다</p></blockquote><table><thead><tr><th>옵션</th><th>설명</th></tr></thead><tbody><tr><td>-m</td><td>match 여부로 패킷의 방향을 결정하는 옵션</td></tr><tr><td>state –state INVALID</td><td>패킷이 network연결되어 있는지 모르는 상태</td></tr><tr><td>state –state ESTABLISHED</td><td>패킷이 network 연결되어 있는 상태</td></tr><tr><td>state –state NEW</td><td>패킷이 network 새로 연결되어 있는 상태</td></tr><tr><td>state –state RELATED</td><td>패킷이 network새로 연결되어 있으나 이미 연결되어 있는 network와 연관성이 있는 상태</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -p tcp --tcp-flags ACK ACK --dport 80 -m string --string <span class="string">"/default.ida?"</span> -j REJECT --reject-with tcp-reset</span><br></pre></td></tr></table></figure><blockquote><p>protocol이(-p) tcp이고 목적지가 80번 포트(–dport 80)로 오는(INPUT) 신호가 ACK이고 /default.ida?라는 문자열이 들어있는 패킷은 연결을 해제하고(tcp-reset) 거절하는(REJECT) 규칙을 추가(A)한다. </p></blockquote><ul><li>reject 옵션</li></ul><table><thead><tr><th>옵션</th><th>설명</th></tr></thead><tbody><tr><td>reject-with tcp-reset</td><td>RST 패킷을 돌려보내서 연결을 해제토록 함</td></tr><tr><td>reject-with icmp-net-unreachable</td><td>error 메시지를 돌려보냄</td></tr><tr><td>reject-with icmp-host-unreachable</td><td>error 메시지를 돌려보냄</td></tr><tr><td>reject-with icmp-port-unreachable</td><td>error 메시지를 돌려보냄</td></tr><tr><td>reject-with icmp-proto-unreachable</td><td>error 메시지를 돌려보냄</td></tr><tr><td>reject-with icmp-net-prohibitedor</td><td>error 메시지를 돌려보냄</td></tr><tr><td>reject-with icmp-host-prohibited</td><td>error 메시지를 돌려보냄</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A input -i eth0 -s 10.0.0.0/8 -d 0/0 -j DENY</span><br><span class="line">$ iptables -A input -i eth0 -s 127.0.0.0/8 -d 0/0 -j DENY</span><br><span class="line">$ iptables -A input -i eth0 -s 172.16.0.0/16 -d 0/0 -j DENY</span><br><span class="line">$ iptables -A input -i eth0 -s 192.168.0.0/24 -d 0/0 -j DENY</span><br></pre></td></tr></table></figure><blockquote><p>외부에서 내부 네트워크 IP자격으로 접근하여 ip spoofing하는 것 방지</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A POSTROUTING -o ppp0 -j MASQUERADE</span><br></pre></td></tr></table></figure><blockquote><p>IP 주소를 할당 받은후 (POSTROUTING) NAT 테이블에 (-t nat) 서버밖으로 나가는 인터페이스(-o)가 ppp0인 모든 패킷들이 마스쿼레이드 되도록 (-j MASQUERADE) 규칙을 추가(-A) 한다.  * ppp0는 활성화된 외부 디바이스(External Interface)가 유동IP인 경우이며, 고정IP인 경우 ppp0대신에 eth0사용 (/sbin/ifconfig를 이용하여 활성화된 외부 디바이스 확인 가능)</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A POSTROUTING -o ppp0 -j MASQUERADE</span><br><span class="line">$ <span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><blockquote><p>유동(또는 고정) IP 한개인 서버를 통해 IP가 없는 PC에 인터넷 연결가능하게 함</p><p>PREROUTING : 서버안으로 들어오는 패킷에 해당되며, 들어오는 인터페이스(-i)만 선택 가능</p><p>POSTROUTING : 서버밖으로 나가는 패킷에 해당되면, 나가는 인터페이스(-o)만 선택 가능</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to 1.2.3.4</span><br></pre></td></tr></table></figure><blockquote><p>외부로 나가는 패킷의 출발지를 현재 내 PC의 IP주소인 200.200.200.200이 아닌 1.2.3.4로 변경</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -A INPUT -s 127.0.0.1 -p icmp -j DROP</span><br></pre></td></tr></table></figure><blockquote><p>127.0.0.1로부터의 모든 ICMP 패킷을 DROP한다.</p></blockquote><h2 id="참조"><a href="#참조" class="headerlink" title="참조"></a>참조</h2><p><a href="http://xenostudy.tistory.com/245" target="_blank" rel="noopener">http://xenostudy.tistory.com/245</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;netfilter란&quot;&gt;&lt;a href=&quot;#netfilter란&quot; class=&quot;headerlink&quot; title=&quot;netfilter란?&quot;&gt;&lt;/a&gt;netfilter란?&lt;/h2&gt;&lt;p&gt;커널에서 패킷을 필터링 하는 모듈. iptables 가 netfi
      
    
    </summary>
    
      <category term="DevOps" scheme="https://sacoku.github.io/categories/DevOps/"/>
    
      <category term="Linux" scheme="https://sacoku.github.io/categories/DevOps/Linux/"/>
    
    
      <category term="Linux" scheme="https://sacoku.github.io/tags/Linux/"/>
    
      <category term="iptables" scheme="https://sacoku.github.io/tags/iptables/"/>
    
  </entry>
  
  <entry>
    <title>인피니밴드 IPoIB로 Layer2 제어</title>
    <link href="https://sacoku.github.io/2018/07/13/infiniband-ipoib-layer2/"/>
    <id>https://sacoku.github.io/2018/07/13/infiniband-ipoib-layer2/</id>
    <published>2018-07-13T02:03:22.000Z</published>
    <updated>2018-07-13T02:14:28.299Z</updated>
    
    <content type="html"><![CDATA[<p>작성예정(deprecated 된 EIpoIB 포팅)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;작성예정(deprecated 된 EIpoIB 포팅)&lt;/p&gt;

      
    
    </summary>
    
      <category term="Deveop" scheme="https://sacoku.github.io/categories/Deveop/"/>
    
      <category term="Network" scheme="https://sacoku.github.io/categories/Deveop/Network/"/>
    
    
      <category term="Infiniband" scheme="https://sacoku.github.io/tags/Infiniband/"/>
    
      <category term="IpoIB" scheme="https://sacoku.github.io/tags/IpoIB/"/>
    
  </entry>
  
  <entry>
    <title>Alpine Linux에서 Timezone 세팅</title>
    <link href="https://sacoku.github.io/2018/07/13/alpine-linux-timezone/"/>
    <id>https://sacoku.github.io/2018/07/13/alpine-linux-timezone/</id>
    <published>2018-07-13T01:57:10.000Z</published>
    <updated>2018-07-13T01:59:01.432Z</updated>
    
    <content type="html"><![CDATA[<p>Docker로 Image를 만들다 보면, Alpine Linux Base로 할 경우가 많은데, 로그 생성 시, Timezone 문제로</p><p>로깅에 어려움을 겪는 경우가 있다. 이 경우 아래의 명령으로 Timezone 문제로 해결 할 수 있다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ apk add tzdata</span><br><span class="line">$ cp /usr/share/zoneinfo/Asia/Seoul /etc/localtime</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Docker로 Image를 만들다 보면, Alpine Linux Base로 할 경우가 많은데, 로그 생성 시, Timezone 문제로&lt;/p&gt;
&lt;p&gt;로깅에 어려움을 겪는 경우가 있다. 이 경우 아래의 명령으로 Timezone 문제로 해결 할 수 있
      
    
    </summary>
    
      <category term="DevOps" scheme="https://sacoku.github.io/categories/DevOps/"/>
    
      <category term="Linux" scheme="https://sacoku.github.io/categories/DevOps/Linux/"/>
    
    
      <category term="Docker" scheme="https://sacoku.github.io/tags/Docker/"/>
    
      <category term="Alpine Linux" scheme="https://sacoku.github.io/tags/Alpine-Linux/"/>
    
      <category term="Timezone" scheme="https://sacoku.github.io/tags/Timezone/"/>
    
  </entry>
  
  <entry>
    <title>GIT CRLF 문제</title>
    <link href="https://sacoku.github.io/2018/07/13/git-crlf/"/>
    <id>https://sacoku.github.io/2018/07/13/git-crlf/</id>
    <published>2018-07-12T23:42:05.000Z</published>
    <updated>2018-07-13T01:22:09.714Z</updated>
    
    <content type="html"><![CDATA[<p>Git을 사용하다 보면, Client 환경이 Windows/Linux 등 다른 환경일 경우가 있다.<br>이 경우 서로 다른 line ending으로 인해서 수정이 되지 않았음에도 수정된 것으로 인식하여 협업 시 어려움이 발생하는 경우가 있다.<br>이러한 문제를 해결하기 위해서는 git의 아래의 설정이 필요하다.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global core.autocrlf input</span><br><span class="line">$ git config --global core.eol lf</span><br></pre></td></tr></table></figure></p><ul><li>core.autocrlf</li></ul><table><thead><tr><th>options</th><th><center>value</center></th></tr></thead><tbody><tr><td>false</td><td>기본설정. 파일에 CRLF 를 썼든 LF 를 썼든 git 은 상관하지 않고 파일 그대로 checkin, checkout 한다. 이 설정은 line ending 이 다른 OS 에서는 text file 이 변경되었다고 나오므로 위에서 언급한 여러 가지 문제가 발생할 수 있다</td></tr><tr><td>true</td><td>text file을 object database 에 넣기전에 CRLF 를 LF 로 변경한다</td></tr><tr><td>input</td><td>LF를 line ending 으로 사용한다.</td></tr></tbody></table><ul><li>core.eol</li></ul><table><thead><tr><th>options</th><th><center>value</center></th></tr></thead><tbody><tr><td>native</td><td>기본 설정. 시스템에서 line ending 을 처리하는 방법에 따른다. windows에서는 CRLF 를 사용하고 Linux, OS X 는 LF 만 사용한다.</td></tr><tr><td>crlf</td><td>CRLF 를 line ending 으로 사용한다.</td></tr><tr><td>lf</td><td>LF를 line ending 으로 사용한다.</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Git을 사용하다 보면, Client 환경이 Windows/Linux 등 다른 환경일 경우가 있다.&lt;br&gt;이 경우 서로 다른 line ending으로 인해서 수정이 되지 않았음에도 수정된 것으로 인식하여 협업 시 어려움이 발생하는 경우가 있다.&lt;
      
    
    </summary>
    
      <category term="DevOps" scheme="https://sacoku.github.io/categories/DevOps/"/>
    
      <category term="Git" scheme="https://sacoku.github.io/categories/DevOps/Git/"/>
    
    
      <category term="Git" scheme="https://sacoku.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>2018-07-12</title>
    <link href="https://sacoku.github.io/2018/07/12/2018-07-12/"/>
    <id>https://sacoku.github.io/2018/07/12/2018-07-12/</id>
    <published>2018-07-12T07:49:27.000Z</published>
    <updated>2018-07-13T01:23:05.356Z</updated>
    
    <content type="html"><![CDATA[<p>처음으로 Blog용 페이지 만듬<br><img src="/images/sons.jpg" alt="아들들"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;처음으로 Blog용 페이지 만듬&lt;br&gt;&lt;img src=&quot;/images/sons.jpg&quot; alt=&quot;아들들&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
      <category term="Blog" scheme="https://sacoku.github.io/categories/Blog/"/>
    
      <category term="2018" scheme="https://sacoku.github.io/categories/Blog/2018/"/>
    
    
      <category term="Sons" scheme="https://sacoku.github.io/tags/Sons/"/>
    
  </entry>
  
  <entry>
    <title>Docker Build &amp; Run</title>
    <link href="https://sacoku.github.io/2018/07/12/docker-build-run/"/>
    <id>https://sacoku.github.io/2018/07/12/docker-build-run/</id>
    <published>2018-07-12T07:24:21.000Z</published>
    <updated>2018-07-13T01:22:45.874Z</updated>
    
    <content type="html"><![CDATA[<p>Docker로 Image를 생성해서 Docker-compose로 실행하는 방법에 대해서 서술해<br>보자 한다.</p><h2 id="Docker-Build-Image-만들기"><a href="#Docker-Build-Image-만들기" class="headerlink" title="Docker Build Image 만들기"></a>Docker Build Image 만들기</h2><p>아래는 Dockerfile 의 기본적인 작성 예이다.<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">FROM</span> <span class="attr">openjdk:8u171-jdk-alpine3.7</span>  <span class="comment">#Base Image</span></span><br><span class="line"><span class="string">MAINTAINER</span> <span class="string">Sunghyun</span> <span class="string">Kim(sacoku@metabuild.co.kr)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Environment Variable</span></span><br><span class="line"><span class="string">ENV</span> <span class="string">KRF_HOME=/usr/local/apache-karaf</span></span><br><span class="line"><span class="string">ENV</span> <span class="string">KFA_HOME=/usr/local/kafka</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Apk Update</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">apk</span> <span class="bullet">--update</span> <span class="string">upgrade</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">apk</span> <span class="bullet">--update</span> <span class="string">add</span> <span class="string">sudo</span> <span class="string">bash</span> <span class="string">jq</span> <span class="string">curl</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">rm</span> <span class="bullet">-rf</span> <span class="string">/var/cache/apk/*</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## karaf install</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">wget</span> <span class="attr">http://apache.tt.co.kr/karaf/4.2.0/apache-karaf-4.2.0.tar.gz</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">tar</span> <span class="string">xvzf</span> <span class="string">apache-karaf-4.2.0.tar.gz</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mv</span> <span class="string">apache-karaf-4.2.0</span> <span class="string">/usr/local</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mkdir</span> <span class="bullet">-p</span> <span class="string">/usr/local/apache-karaf-4.2.0/config/radar</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mkdir</span> <span class="bullet">-p</span> <span class="string">/usr/local/apache-karaf-4.2.0/config/vsl</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">rm</span> <span class="string">apache-karaf-4.2.0.tar.gz</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">ln</span> <span class="bullet">-s</span> <span class="string">/usr/local/apache-karaf-4.2.0</span> <span class="string">/usr/local/apache-karaf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## kafka install</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">wget</span> <span class="attr">http://apache.tt.co.kr/kafka/1.1.0/kafka_2.12-1.1.0.tgz</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">tar</span> <span class="string">xvzf</span> <span class="string">kafka_2.12-1.1.0.tgz</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mv</span> <span class="string">kafka_2.12-1.1.0</span> <span class="string">/usr/local</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">rm</span> <span class="string">kafka_2.12-1.1.0.tgz</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">ln</span> <span class="bullet">-s</span> <span class="string">/usr/local/kafka_2.12-1.1.0</span> <span class="string">/usr/local/kafka</span></span><br><span class="line"></span><br><span class="line"><span class="string">COPY</span> <span class="string">configs/bundle/*</span> <span class="string">$KRF_HOME/deploy/</span></span><br><span class="line"><span class="string">COPY</span> <span class="string">configs/config/radar</span> <span class="string">$KRF_HOME/config/radar</span></span><br><span class="line"><span class="string">COPY</span> <span class="string">configs/config/vsl</span> <span class="string">$KRF_HOME/config/vsl</span></span><br><span class="line"><span class="string">COPY</span> <span class="string">configs/karaf.sh</span> <span class="string">/root</span></span><br><span class="line"><span class="string">COPY</span> <span class="string">configs/kafka.sh</span> <span class="string">/root</span></span><br><span class="line"></span><br><span class="line"><span class="string">CMD</span> <span class="string">[</span> <span class="string">"sh"</span><span class="string">,</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"/root/karaf.sh start; /root/kafka.sh start"</span> <span class="string">]</span></span><br><span class="line"></span><br><span class="line"><span class="string">EXPOSE</span> <span class="number">1099</span> <span class="number">8101</span> <span class="number">44444</span> <span class="number">8181</span></span><br></pre></td></tr></table></figure></p><h2 id="Docker-build"><a href="#Docker-build" class="headerlink" title="Docker build"></a>Docker build</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -it metabuild/vsls-karaf .</span><br></pre></td></tr></table></figure><h2 id="Docker-Compose-스크립트"><a href="#Docker-Compose-스크립트" class="headerlink" title="Docker Compose 스크립트"></a>Docker Compose 스크립트</h2><p>아래는 docker-compose.yml 파일의 container 간 Link를 사용하는 기본적인 사용 예이다.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  vsls-server:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">metabuild/vsls-karaf</span></span><br><span class="line"><span class="attr">    container_name:</span> <span class="string">vsls-karaf</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">vsls-server</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">vsls-net</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="number">2181</span><span class="string">:2181</span></span><br><span class="line"><span class="bullet">      -</span> <span class="number">9092</span><span class="string">:9092</span></span><br><span class="line"><span class="bullet">      -</span> <span class="number">8181</span><span class="string">:8181</span></span><br><span class="line"><span class="bullet">      -</span> <span class="number">6500</span><span class="string">:6500</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="attr">      ADVERTISED_HOST:</span> <span class="string">vsls-server</span></span><br><span class="line"><span class="attr">      ADVERTISED_PORT:</span> <span class="number">9092</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  vsls-web:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">metabuild/vsls-web</span></span><br><span class="line"><span class="attr">    container_name:</span> <span class="string">vsls-web</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="number">81</span><span class="string">:81</span></span><br><span class="line"><span class="bullet">      -</span> <span class="number">8082</span><span class="string">:8082</span></span><br><span class="line"><span class="bullet">      -</span> <span class="number">9000</span><span class="string">:9000</span></span><br><span class="line"><span class="attr">    links:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">vsls-server</span> <span class="comment"># vsls-server와 link되어서 </span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line"><span class="attr">  vsls-net:</span></span><br><span class="line"><span class="attr">    driver:</span> <span class="string">bridge</span></span><br></pre></td></tr></table></figure><h2 id="Docker-실행"><a href="#Docker-실행" class="headerlink" title="Docker 실행"></a>Docker 실행</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose up -d</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Docker로 Image를 생성해서 Docker-compose로 실행하는 방법에 대해서 서술해&lt;br&gt;보자 한다.&lt;/p&gt;
&lt;h2 id=&quot;Docker-Build-Image-만들기&quot;&gt;&lt;a href=&quot;#Docker-Build-Image-만들기&quot; clas
      
    
    </summary>
    
      <category term="DevOps" scheme="https://sacoku.github.io/categories/DevOps/"/>
    
      <category term="Docker" scheme="https://sacoku.github.io/categories/DevOps/Docker/"/>
    
    
      <category term="Docker" scheme="https://sacoku.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker Summary</title>
    <link href="https://sacoku.github.io/2018/07/12/docker-summary/"/>
    <id>https://sacoku.github.io/2018/07/12/docker-summary/</id>
    <published>2018-07-12T03:37:37.000Z</published>
    <updated>2018-07-13T00:30:13.472Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>Dockerfile build<br>Dockerfile이 있는 디렉토리에서 아래의 명령어를 실행</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t [tag] .</span><br></pre></td></tr></table></figure></li><li><p>Docker 실행</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -p 8080:8081 -p 1234:1111 -v /var/tmp:/data [image name]</span><br></pre></td></tr></table></figure></li><li><p>Docker container List 확인</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps -a</span><br></pre></td></tr></table></figure></li><li><p>Docker image List 확인</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker images</span><br></pre></td></tr></table></figure></li><li><p>Docker image 삭제</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker rmi [image id]</span><br></pre></td></tr></table></figure></li><li><p>Docker Container 삭제</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker rm [Container ID]</span><br></pre></td></tr></table></figure></li><li><p>Docker Container  Start/Stop</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker start/stop [Container ID]</span><br></pre></td></tr></table></figure></li><li><p>Docker Volume 생성 &amp; 실행</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume create --name data</span><br><span class="line">$ docker run --name=test -p 10022:22 -v data:/data [image]</span><br></pre></td></tr></table></figure></li><li><p>Docker Container 명령어 싫행</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it [Container ID] [Command]</span><br></pre></td></tr></table></figure></li><li><p>Container를 Image로 만들기</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker commit [options] &lt;container name&gt; [image name[:tag name]]</span><br><span class="line"># example</span><br><span class="line">$ docker commit -a &quot;catchup&quot; -m &quot;www.leafcats.com&quot; nginx_base catchup/myapp</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody><tr><td>- a, –author=””</td><td>생성자 정보</td></tr><tr><td>-m, –message=””</td><td>이미지 메시지</td></tr><tr><td>-p, –pause=true/false</td><td>이미지를 생성할 때 컨테이너를 중지(stop) 한 뒤 commit 여부</td></tr></tbody></table><h3 id="Docker-Image-import-export"><a href="#Docker-Image-import-export" class="headerlink" title="Docker Image import/export"></a>Docker Image import/export</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># export</span></span><br><span class="line">$ docker save image_name &gt; ./backup.tar</span><br><span class="line"><span class="comment"># import</span></span><br><span class="line">$ docker load -i ./backup.tar</span><br></pre></td></tr></table></figure><h3 id="Docker-Container-import-export"><a href="#Docker-Container-import-export" class="headerlink" title="Docker Container import/export"></a>Docker Container import/export</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># export</span></span><br><span class="line">$ docker <span class="built_in">export</span> [container_name] &gt; ./backup.tar</span><br><span class="line"><span class="comment"># import</span></span><br><span class="line">$ docker import ./backup.tar</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;p&gt;Dockerfile build&lt;br&gt;Dockerfile이 있는 디렉토리에서 아래의 명령어를 실행&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;spa
      
    
    </summary>
    
      <category term="DevOps" scheme="https://sacoku.github.io/categories/DevOps/"/>
    
      <category term="Docker" scheme="https://sacoku.github.io/categories/DevOps/Docker/"/>
    
    
      <category term="Docker" scheme="https://sacoku.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>How to Hadoop HDFS NFS</title>
    <link href="https://sacoku.github.io/2018/07/12/how-to-hadoop-hdfs-nfs/"/>
    <id>https://sacoku.github.io/2018/07/12/how-to-hadoop-hdfs-nfs/</id>
    <published>2018-07-12T00:07:49.000Z</published>
    <updated>2018-07-13T01:21:52.876Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Hadoop은 NFS Gateway를 지원 해준다. 근데, 공식 문서에서는 exports point를 직접 지정 하는 방법은 나와있지 않다.</p><h3 id="1-hdfs-site-xml-nfs-옵션-추가"><a href="#1-hdfs-site-xml-nfs-옵션-추가" class="headerlink" title="1. hdfs-site.xml nfs 옵션 추가"></a>1. hdfs-site.xml nfs 옵션 추가</h3><p>이 값은 hadoop 2.5.x 버전 이상에서만 존재함</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nano <span class="variable">$HADOOP_PREFIX</span>/etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">......................................</span><br><span class="line">...........................................</span><br><span class="line">................................................</span><br><span class="line">    <span class="comment">&lt;!-- NFS v3 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>nfs.exports.allowed.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>* rw<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>nfs.export.point<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/ruo91<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!-- HDFS상에 실제 존재해야 하는 디렉토리여야 함 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>Property</th><th>Description</th></tr></thead><tbody><tr><td>hadoop.proxyuser.[userid].groups</td><td>NFS를 마운트를 허용할 사용자</td></tr><tr><td>hadoop.proxyuser.[userid].hosts</td><td>이 옵션에 값을 *로 설정하면 모든 호스트들에게 NFS Gateway 허용</td></tr><tr><td>nfs.exports.allowed.hosts</td><td>NFS Client가 Mount시 허용할 Host와 권한을 지정할때 사용한다.</td></tr><tr><td>nfs.export.point</td><td>NFS의 exports point를 직접 지정할 수 있는 부분이다.</td></tr></tbody></table><h3 id="2-Data-Node-재시작"><a href="#2-Data-Node-재시작" class="headerlink" title="2. Data Node 재시작"></a>2. Data Node 재시작</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ stop-dfs.sh all &amp;&amp; start-dfs.sh</span><br></pre></td></tr></table></figure><h3 id="3-Hadoop-NFS-Gateway"><a href="#3-Hadoop-NFS-Gateway" class="headerlink" title="3. Hadoop NFS Gateway"></a>3. Hadoop NFS Gateway</h3><p>HostOS에 기존에 동작하고 있던 portmap, nfs 서비스를 사전에 모두 중지 해야한다.<br>(물론 사용하는 OS에 따라 서비스 중지법은 다르다.)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ service nfs stop &amp;&amp; service rpcbind</span><br></pre></td></tr></table></figure></p><p>Hadoop의 Portmap, NFS 서버를 실행하는 방법은 2가지가 있다.<br>첫번째는 hadoop-daemon.sh 스크립트를 사용하여 background에서 실행하는 방법.<br>두번째는 hdfs 명령어를 통해 foreground에서 실행하는 방법이 있다.</p><p>본인은 정상 Mount 되었는지 확인 하기 위해서 두번째 방법으로 실행 하겠다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs portmap &amp;</span><br><span class="line">$ hdfs nfs3 &amp;</span><br></pre></td></tr></table></figure></p><h3 id="4-Test"><a href="#4-Test" class="headerlink" title="4. Test"></a>4. Test</h3><p>정상적으로 Mount 되었는지 확인하기 위해 HDFS에 디렉토리를 만들고, 임의로 생성한 파일을 복사하여 NFS Client에서 Mount 해볼 것이다.</p><ul><li>로그 생성 및 복사<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs -mkdir -p /ruo91/logs</span><br><span class="line">$ <span class="keyword">for</span>((i=0; i&lt;10; i++)) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">$&#123;i&#125;</span>; <span class="keyword">done</span> &gt; /tmp/test.log</span><br><span class="line">$ hdfs dfs -copyFromLocal /tmp/test.log /ruo91/logs/test.log</span><br><span class="line">$ hdfs dfs -ls -R /ruo91</span><br><span class="line"></span><br><span class="line">drwxr-xr-x   - root supergroup          0 2015-02-11 23:35 /ruo91/logs</span><br><span class="line">-rw-r--r--   1 root supergroup         20 2015-02-11 23:35 /ruo91/logs/test.log</span><br><span class="line">-rw-r--r--   1 root supergroup 1160435178 2015-02-11 22:24 /ruo91/logs/yongbok.net-access-logs.json</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>NFS Client Mount 테스트<br>exports point 확인</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ showmount -e</span><br><span class="line">Export list <span class="keyword">for</span> ruo91:</span><br><span class="line">/ruo91 *</span><br></pre></td></tr></table></figure></li><li><p>디렉토리 생성 및 mount</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir /hdfs-nfs3</span><br><span class="line">$ mount -t nfs -o vers=3,proto=tcp,nolock localhost:/ruo91 /hdfs-nfs3</span><br></pre></td></tr></table></figure></li><li><p>mount 디렉토리 확인</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ mount | grep hdfs</span><br><span class="line">localhost:/ruo91 on /hdfs-nfs3 <span class="built_in">type</span> nfs (rw,vers=3,proto=tcp,nolock,addr=127.0.0.1)</span><br><span class="line"></span><br><span class="line">$ ls -alR /hdfs-nfs3  </span><br><span class="line">root@ruo91:~<span class="comment"># ls -alR /hdfs-nfs3</span></span><br><span class="line"></span><br><span class="line">/hdfs-nfs3:</span><br><span class="line">total 5</span><br><span class="line">drwxr-xr-x  3 root 2584148964   96  2월 11 22:23 .</span><br><span class="line">drwxr-xr-x 27 root root       4096  2월 11 22:22 ..</span><br><span class="line">drwxr-xr-x  4 root 2584148964  128  2월 11 23:35 logs</span><br><span class="line"></span><br><span class="line">/hdfs-nfs3/logs:</span><br><span class="line">total 1133239</span><br><span class="line">drwxr-xr-x 4 root 2584148964        128  2월 11 23:35 .</span><br><span class="line">drwxr-xr-x 3 root 2584148964         96  2월 11 22:23 ..</span><br><span class="line">-rw-r--r-- 1 root 2584148964         20  2월 11 23:35 test.log</span><br><span class="line">-rw-r--r-- 1 root 2584148964 1160435178  2월 11 22:24 yongbok.net-access-logs.json</span><br></pre></td></tr></table></figure></li></ul><p>위와 같이 정상적으로 마운트가 되면 Hadoop NFS 서버에는 아래와 같은 INFO 메세지가 나오면 잘 된거다.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">15/02/11 23:42:16 INFO mount.RpcProgramMountd: Giving handle (fileId:16386) to client <span class="keyword">for</span> <span class="built_in">export</span> /ruo91</span><br></pre></td></tr></table></figure></p><ul><li><p>윈도우에서 접근시</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ mount -o anon \\10.1.2.221\user\root\data Z:</span><br><span class="line">명령을 완료했습니다.</span><br><span class="line"></span><br><span class="line">$ mount</span><br><span class="line">로컬    원격                                 속성</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">r:       \\10.1.2.221\user\root\data            UID=0, GID=0</span><br><span class="line">                                                rsize=1048576, wsize=1048576</span><br><span class="line">                                                mount=soft, timeout=0.8</span><br><span class="line">                                                retry=1, locking=no</span><br><span class="line">                                                fileaccess=755, lang=KSC5601</span><br><span class="line">                                                casesensitive=no</span><br><span class="line">                                                sec=sys</span><br></pre></td></tr></table></figure><p>anon:anonymouns default uid/gid가 -2로 설정 되어 있기 때문에 변경이 필요하다.<br>변경은 “HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\ClientForNFS\CurrentVersion\Default”에 아래의 값을 설정해야 한다.</p></li></ul><table><thead><tr><th>Name</th><th>Type</th><th>Data</th></tr></thead><tbody><tr><td>AnonymounsUid</td><td>REG_DWORD</td><td>0x00000000(0)</td></tr><tr><td>AnonymounsGid</td><td>REG_DWORD</td><td>0x00000000(0)</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Apache Hadoop은 NFS Gateway를 지원 해준다. 근데, 공식 문서에서는 exports point를 직접 지정 하는 방법은 나와있지 않다.&lt;/p&gt;
&lt;h3 id=&quot;1-hdfs-site-xml-nfs-옵션-추가&quot;&gt;&lt;a href=&quot;#1-
      
    
    </summary>
    
      <category term="Bigdata" scheme="https://sacoku.github.io/categories/Bigdata/"/>
    
      <category term="Hadoop" scheme="https://sacoku.github.io/categories/Bigdata/Hadoop/"/>
    
    
      <category term="Bigdata" scheme="https://sacoku.github.io/tags/Bigdata/"/>
    
      <category term="Hadoop" scheme="https://sacoku.github.io/tags/Hadoop/"/>
    
  </entry>
  
</feed>
