{"meta":{"title":"sacoku's github.io","subtitle":"Develop History","description":null,"author":"sacoku","url":"https://sacoku.github.io"},"pages":[{"title":"","date":"2018-07-19T06:09:27.166Z","updated":"2018-07-12T00:26:17.022Z","comments":true,"path":"about/index.html","permalink":"https://sacoku.github.io/about/index.html","excerpt":"","text":""},{"title":"","date":"2018-07-19T06:09:27.166Z","updated":"2018-07-12T00:28:18.726Z","comments":true,"path":"404/index.html","permalink":"https://sacoku.github.io/404/index.html","excerpt":"","text":""}],"posts":[{"title":"FFMPEG ������ ���","slug":"ffmpeg-windows-build","date":"2018-10-15T00:37:00.000Z","updated":"2018-10-15T00:41:42.227Z","comments":true,"path":"2018/10/15/ffmpeg-windows-build/","link":"","permalink":"https://sacoku.github.io/2018/10/15/ffmpeg-windows-build/","excerpt":"","text":"FFMpeg windows build(x64)��ġ��, Visual C++�� �����Ϸ�(cl)�� �̿��ؼ� ��� �ϹǷ� Visual C++ �� ��ġ �Ǿ� �־�� �� msys2 ��ġ(http://www.msys2.org)���� Linux ȯ���� �����ϸ� gcc�� ����Ͽ� ������ exe�� ����� �� �� �ִ�. msys2 ���� ���־� ��Ʃ����� x64 ������ ������ �Ʒ��� ��ɾ �����Ѵ�. 1c:\\msys2&gt; msys2_shell.cmd -use-full-path -mingw64 �ʼ� ��Ű�� ��ġ. 123$ pacman -S make gcc diffutils$ pacman -S pkg-config$ pacman -S yasm nasm ��Ŀ �̸� ���� MSVC�� ��Ŀ�� �浹�� �߻��� �� �ֱ� ������ msys2�� link.exe�� �̸��� �����Ѵ�.(ex:link_org.exe) cl Ȯ�� �Ʒ��� ��ɾ�� x64 cl�� ��ΰ� ���� �Ǿ� �ִ��� Ȯ��(cl�� ��ġ�� ������ �Ǿ� �־�� �Ѵ�.) 12$ which cl$ which link x264 ��ġ x264 �ٿ�ε�(http://www.videolan.org/developers/x264.html) 1$ git clone http://git.videolan.org/git/x264.git ��� &amp;&amp; ��ġ 12$ ./configure --enable-shared$ make &amp;&amp; make install FFMPEG ��ġ FFMPEG �ٿ�ε� 1$ git clone https://git.ffmpeg.org/ffmpeg.git ��� &amp;&amp; ��ġ 1234$ ./configure --toolchain=msvc --arch=x86_64 --enable-shared \\ --enable-gpl --disable-doc --enable-d3d11va \\ --enable-dxva2 --prefix=./install$ make &amp;&amp; make install","categories":[{"name":"DevOps","slug":"devops","permalink":"https://sacoku.github.io/categories/devops/"},{"name":"ffmpeg","slug":"devops/ffmpeg","permalink":"https://sacoku.github.io/categories/devops/ffmpeg/"}],"tags":[{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://sacoku.github.io/tags/ffmpeg/"}]},{"title":"Iptables 일반사항","slug":"how-to-iptables","date":"2018-07-13T08:00:11.000Z","updated":"2018-07-13T08:30:08.794Z","comments":true,"path":"2018/07/13/how-to-iptables/","link":"","permalink":"https://sacoku.github.io/2018/07/13/how-to-iptables/","excerpt":"","text":"netfilter란?커널에서 패킷을 필터링 하는 모듈. iptables 가 netfilter 커널 모듈을 이용하여 패킷을 필터링 한다. 즉, iptables를 이용하여 패킷 룰-셋을 구축하며 netfilter가 룰셋에 따라서 패킷을 필터링 등의 역활을 수행한다. iptables란 iptables에는 세가지 chain이 있고 모든 패킷은 이 세가지 chain중 하나를 통과하게 된다. 이 세가지 chain은 INPUT, OUTPUT, FORWARD chain인데 우선 여러분의 컴퓨터로 들어가는 모든 패킷은 INPUT chain을 통과한다. 그리고 여러분의 컴퓨터에서 나가는 모든 패킷은 OUTPUT chain을 통과한다. 그리고 하나의 네트워크에서 다른 곳으로 보내는 모든 패킷은 FORWARD chain 을 통과한다. iptables가 작동하는 방식은 이들 각각의 INPUT, OUTPUT, FORWARD chain에 당신이 어떠한 rule을 세우는 지에 따라 달라진다. 예를 들어 당신이 HTML 페이지를 요청하기 위해 http://www.yahoo.com에 패킷을 보낸다면 이 패킷은 우선 당신 컴퓨터의 OUTPUT chain을 통과하게 된다. 그러면 kernel에서 OUTPUT chain의 rule을 확인하고 rule과 match가 되는지 확인을 하게 된다. rule중에서 최초로 match되는 것에 의해 당신이 보낸 패킷의 운명이 결정되는 것이다. 만약 어떤 rule과도 match되지 않는다면 전체 chain의 정책이 ACCEPT냐 DROP이냐에 따라 패킷의 운명이 결정될 것이다. 그러고 나서 Yahoo! 에서 응답하는 패킷은 당신의 INPUT chain을 통과하게 될 것이다 iptables로 할 수 있는 일에는 몇가지 다른 것이 있다. 첫번째 작동은 전체 체인을 조절한다. 처음 시작은 세개의 미리 만들어진 체인으로 시작하는 데 이것은 제거될 수 없다 iptables는 모듈로 되어있을 것이다. 이것은 iptable_filter.o 이다. 이것은 처음으로 iptables를 실행 할 때 자동으로 로드 될 것이다. 이것은 커널에 영구히 포함될 수도 있다 iptables 명령이 실행되기 전에는 기본적으로 만들어져 있는 체인 INPUT, FORWARDING, OUTPUT chain에는 아무런 규칙도 없다. 기본 Chain12345&amp;nbsp------&gt;INPUT------&gt; Linux Box ------&gt;OUTPUT---------&gt;---------↕-----------------------------↕---------└---------- FORWARD ----------┘ Linux box를 도착지로 삼는 모든 패킷은 INPUT Chain을 통과하게 되며 Linux box에서 생성되 외부로 보내지는 모든 패킷은 OUTPUT Chain을 통과하게 된다. Forward chain은 엄밀히 말하자면 도착지가 Linux box가 아닌 패킷이 통과하게 되는 체인이다 Chain의 실행 순서와 사용자 Chain과의 관계iptables의 강력한 기능중의 하나는 사용자가 기존의 세개의 체인 INPUT, OUTPUT, FORWARD chain외에 새로운 체인을 생성할 수 있다는 것이다. 타겟이 사용자 지정의 체인인 규칙에 패킷이 맞으면 패킷은 사용자 지정의 체인을 따라 움직이게 된다. 그 체인이 패킷의 운명을 결정하지 못하면 그리고 그 체인에 따른 이송이 끝나면, 패킷은 현제 체인의 다음 규칙으로 돌아온다 이해를 위해 예를 들자면 아래의 그림은 두개의 체인이 있고 그것이 INPUT 과 test 라는 사용자 지정의 체인이 라고 가정해 보자 12345678 `INPUT&apos; `test&apos; ---------------------------- ----------------------------| Rule1: -p ICMP -j DROP | | Rule1: -s 192.168.1.1 ||--------------------------| |--------------------------|| Rule2: -p TCP -j test | | Rule2: -d 192.168.1.1 ||--------------------------| |--------------------------| | Rule3: -p UDP -j DROP ||--------------------------| 192.168.1.1 로부터 와서 1.2.3.4 로 향하는 TCP 패킷이 있다고 가정해보자. 이것은 입력 체인으로 들어온다. Rule1 을 검사한다. =&gt; 맞지 않음 Rule2 맞음. 타겟은 “test”, 고로 다음 검사할 규칙은 “test” 의 시작이다 test의 Rule1 이 맞다. 그러나 이것이 타겟을 지정하지 않는다. 그러므로 다음 규칙이 검사된다 Rule 2. 맞지 않음. 체인의 끝에 도달. 다시 입력 체인으로 돌아가서 Rule3 을 검사 한다. 그것도 맞지 않음 그러므로 Drop 시켜 버림 패킷의 이동경로를 그림으로 나타내보자 12345678910 v __________________________ `INPUT&apos; | / `test&apos; v------------------------|--/ -----------------------|----| Rule1 | /| | Rule1 | ||-----------------------|/-| |----------------------|---|| Rule2 / | | Rule2 | ||--------------------------| -----------------------v----| Rule3 /--+___________________________/------------------------|--- v 사용자 지정의 체인에서 대를 사용자 지정의 체인으로 갈수 있다. (그러나 루프를 돌 수는 없다. 루프를 발견하게 되면 패킷은 DROP 된다. Rule의 순서iptables의 chain에서는 먼저 등록 된 rule이 효력을 발생하기때문에 등록을 하는 순서가 중요하다. 모든 것을 거부하는 설정이 먼저 오게 되면 그 이후에 포트를 열어주는 설정이 와도 효과가 없다. 그러므로 허용하는 정책이 먼저 오고 나서 거부하는 정책이 와야 한다. -A 옵션을 줌으로써 우리는 새로운 규칙을 chain의 맨 아래에 추가하게 된다. 즉 chain상의 상위 rule이 먼저 작동하기 때문에, 만일 새로 추가하는 rule을 먼저 작동시키기 위해서는 -I 옵션을 줌으로써 새로운 rule을 원하는 위치에 놓을 수 있다. 예를 들어 INPUT chain의 가장 위에 어떤 rule을 놓고 싶다면 “-I INPUT 1” 이라 명령하면 된다. 그리고 다른 위치로 놓고 싶다면 1을 다른 숫자로 바꿔주면 된다. 이미 위치된 rule을 다른 위치로 바꾸고 싶다면 -R 옵션을 주면 된다. -I 옵션을 주는 것과 마찬가지로 사용할 수 있는데 다만 -I옵션을 사용해서 1의 위치에 놓으면 다른 rule들이 밑으로 한 칸씩 내려가는 반면 -R옵션을 사용해서 1의 위치에 놓으면 그 위치의 rule은 삭제된다. rule을 삭제하고 싶다면 -D옵션과 숫자를 사용하면 되고, -L 옵션을 사용하면 작성된 모든 rule의 목록을 보여주고, -F 옵션을 주면 해당 chain의 모든 rule을 삭제한다. 그리고 만약 chain을 명시하지 않았다면 모든 것을 flush할 것이다. iptables 예제1$ iptables -A INPUT -s 200.200.200.1 -j DROP 200.200.200.1 이라는 source IP(-s)로부터 오는(INPUT) 모든 패킷을 막는(DROP) 규칙을 추가(A)한다. -&gt; 이 한 줄의 명령으로 200.200.200.1로부터 오는 모든 패킷을 무시할 수 있다. 옵션의 순서는 바뀌어도 상관이 없다. 즉 -j DROP이 -s 200.200.200.1 보다 앞에 가도 상관이 없다. 만약 그 반대로 200.200.200.1로 패킷이 못가도록 하려면 INPUT 대신에 OUTPUT을, -s 대신에 -d(destination) 옵션을 주면된다 1$ iptables -A INPUT -p tcp --sport 25 -j ACCEPT 25번이라는 source포트(–sport)에서 오는(INPUT) protocol이(-p) tcp인 모든 접속을 허락하는(ACCEPT) 규칙을 추가(A)한다. -&gt; source port 와 destination port를 혼동하면 안된다. 즉 클라이언트는 어떤 포트로도 작동할 수 있는 반면에 서버는 23번 포트로 작동하기 때문이다. 즉 특정 서비스를 차단하기 위해서는 -destination-port를 이용하면 되고, 그 반대는 -source-port를 이용하면 된다. -&gt; IP의 영역을 선택하고 싶다면 200.200.200.0/24 와 같이 설정하면 된다. 이것은 200.200.200.* 에 해당하는 모든 IP를 선택하는 것과 같다 1$ iptables -A INPUT -s 200.200.200.1 -p tcp --destination-port telnet -j DROP 200.200.200.1 이라는 source IP(-s)로부터 오는(INPUT) protocol이(-p) tcp이고 목적지 port(–destination-port)가 telnet인 패킷의 접속을 막는(DROP) 규칙을 추가(A)한다 1$ iptables -A INPUT -i eth1 -s 192.168.1.0/24 -d 0/0 -j ACCEPT 192.168.1.0/24라는 source IP(-s)로부터 오는(INPUT) 서버안으로 들어오는 인터페이스(-i)가 eth1이고 destination IP(-d)가 어떤 IP라도(0/0) 접속을 허락하는(ACCEPT) 규칙을 추가(A)한다. (서버자체에 대한 접속이 아니라 마스커레이딩등을 이용하여 랜카드 두 개를 장착한 경우 eth1에 연결된 내부 PC에서 외부로의 접속 허용) 1$ iptables -A INPUT -p tcp --destination-port telnet -i ppp0 -j DROP protocol이(-p) tcp이고 목적지 port(–destination-port)가 telnet이며, 서버안으로 들어오는 인터페이스(-i)가 ppp0인 패킷의 접속을 막는(DROP) 규칙을 추가(A)한다. 이렇게 함으로써 우리는 LAN상의 사용자는 telnet을 사용하고 그밖에 Internet상의 사용자는 telnet 을 사용하지 못하도록 할 수 있다 1$ iptables -A INPUT -i ppp0 -p tcp --syn -j DROP ppp0 로 들어오는 모든 tcp의 연결을 무시해버림. 두 컴퓨터가 TCP connection으로 패킷을 주고 받는다면 그 connection은 우선 초기화가 되어야 한다. 이것은 바로 SYN packet이 담당한다. SYN packet은 단순히 다른 컴퓨터에게 주고 받을 준비가 되었다는 것만 알려주는 초기화 기능만을 한다. 이제 서비스를 요청하는 컴퓨터는 우선적으로 SYN packet을 보낸다는 것을 알게 되었다. 그러므로 들어오는 SYN packet만 막기만 하면 다른 컴퓨터가 당신 컴퓨터의 서비스를 이용하지 못하게 할 수 있고, 하지만 당신은 그들과 통신할 수 있는 것이다. 즉 이와 같이 하면 당신이 먼저 패킷을 보내서 요청이 들어오는 것이 아니면 모두 무시해 버리게 된다 1$ iptables -A INPUT -i ppp0 -p tcp --syn --destination-port ! 80 -j DROP 80번 포트만 제외하고 모든 SYN packet들을 막는다. 만약 당신이 웹서비스를 위해 하나의 포트(예를들어 80번-HTTP)만 열어두고 싶다면 역시 한가지 방법이 있다. 바로 “!” 마크를 사용하면 되는데 많은 프로그래밍 언어에서처럼 “!”은 “not”을 의미한다. 예를들어 80번 포트만 제외하고 모든 SYN packet들을 막고싶다면 위와 같이하면된다 12$ iptables -A INPUT -p icmp --icmp-type echo-request -j REJECT $ iptables -A INPUT -p icmp --icmp-type 8 -j REJECT protocol이(-p) icmp이고 icmp 의 type이 echo-request인 패킷이 오는(INPUT) 것을 거절하는(REJECT) 규칙을 추가(A)한다. (외부에서의 ping을 거절하는 방법임 / echo-request대신에 8을 해도 됨 ) 1$ iptables -A INPUT -p tcp --dport 20:30 -j DROP protocol이(-p) tcp이고 목적지 port(–dport)가 20번부터 30번까지인 패킷이 오는(INPUT) 것을 막는(DROP) 규칙을 추가(A)한다. 1$ iptables -A INPUT -m state --state INVALID -j DROP network상태가(state –state)가 INVALID인 패킷이 오는(INPUT) 것을 막는(DROP) 규칙을 추가(A)한다 옵션 설명 -m match 여부로 패킷의 방향을 결정하는 옵션 state –state INVALID 패킷이 network연결되어 있는지 모르는 상태 state –state ESTABLISHED 패킷이 network 연결되어 있는 상태 state –state NEW 패킷이 network 새로 연결되어 있는 상태 state –state RELATED 패킷이 network새로 연결되어 있으나 이미 연결되어 있는 network와 연관성이 있는 상태 1$ iptables -A INPUT -p tcp --tcp-flags ACK ACK --dport 80 -m string --string \"/default.ida?\" -j REJECT --reject-with tcp-reset protocol이(-p) tcp이고 목적지가 80번 포트(–dport 80)로 오는(INPUT) 신호가 ACK이고 /default.ida?라는 문자열이 들어있는 패킷은 연결을 해제하고(tcp-reset) 거절하는(REJECT) 규칙을 추가(A)한다. reject 옵션 옵션 설명 reject-with tcp-reset RST 패킷을 돌려보내서 연결을 해제토록 함 reject-with icmp-net-unreachable error 메시지를 돌려보냄 reject-with icmp-host-unreachable error 메시지를 돌려보냄 reject-with icmp-port-unreachable error 메시지를 돌려보냄 reject-with icmp-proto-unreachable error 메시지를 돌려보냄 reject-with icmp-net-prohibitedor error 메시지를 돌려보냄 reject-with icmp-host-prohibited error 메시지를 돌려보냄 1234$ iptables -A input -i eth0 -s 10.0.0.0/8 -d 0/0 -j DENY$ iptables -A input -i eth0 -s 127.0.0.0/8 -d 0/0 -j DENY$ iptables -A input -i eth0 -s 172.16.0.0/16 -d 0/0 -j DENY$ iptables -A input -i eth0 -s 192.168.0.0/24 -d 0/0 -j DENY 외부에서 내부 네트워크 IP자격으로 접근하여 ip spoofing하는 것 방지 1$ iptables -t nat -A POSTROUTING -o ppp0 -j MASQUERADE IP 주소를 할당 받은후 (POSTROUTING) NAT 테이블에 (-t nat) 서버밖으로 나가는 인터페이스(-o)가 ppp0인 모든 패킷들이 마스쿼레이드 되도록 (-j MASQUERADE) 규칙을 추가(-A) 한다. * ppp0는 활성화된 외부 디바이스(External Interface)가 유동IP인 경우이며, 고정IP인 경우 ppp0대신에 eth0사용 (/sbin/ifconfig를 이용하여 활성화된 외부 디바이스 확인 가능) 12$ iptables -t nat -A POSTROUTING -o ppp0 -j MASQUERADE$ echo 1 &gt; /proc/sys/net/ipv4/ip_forward 유동(또는 고정) IP 한개인 서버를 통해 IP가 없는 PC에 인터넷 연결가능하게 함 PREROUTING : 서버안으로 들어오는 패킷에 해당되며, 들어오는 인터페이스(-i)만 선택 가능 POSTROUTING : 서버밖으로 나가는 패킷에 해당되면, 나가는 인터페이스(-o)만 선택 가능 1$ iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to 1.2.3.4 외부로 나가는 패킷의 출발지를 현재 내 PC의 IP주소인 200.200.200.200이 아닌 1.2.3.4로 변경 1$ iptables -A INPUT -s 127.0.0.1 -p icmp -j DROP 127.0.0.1로부터의 모든 ICMP 패킷을 DROP한다. 참조http://xenostudy.tistory.com/245","categories":[{"name":"DevOps","slug":"devops","permalink":"https://sacoku.github.io/categories/devops/"},{"name":"Linux","slug":"devops/linux","permalink":"https://sacoku.github.io/categories/devops/linux/"}],"tags":[{"name":"Linux","slug":"linux","permalink":"https://sacoku.github.io/tags/linux/"},{"name":"iptables","slug":"iptables","permalink":"https://sacoku.github.io/tags/iptables/"}]},{"title":"인피니밴드 IPoIB로 Layer2 제어","slug":"infiniband-ipoib-layer2","date":"2018-07-13T02:03:22.000Z","updated":"2018-07-13T02:14:28.299Z","comments":true,"path":"2018/07/13/infiniband-ipoib-layer2/","link":"","permalink":"https://sacoku.github.io/2018/07/13/infiniband-ipoib-layer2/","excerpt":"","text":"작성예정(deprecated 된 EIpoIB 포팅)","categories":[{"name":"Deveop","slug":"deveop","permalink":"https://sacoku.github.io/categories/deveop/"},{"name":"Network","slug":"deveop/network","permalink":"https://sacoku.github.io/categories/deveop/network/"}],"tags":[{"name":"Infiniband","slug":"infiniband","permalink":"https://sacoku.github.io/tags/infiniband/"},{"name":"IpoIB","slug":"ipoib","permalink":"https://sacoku.github.io/tags/ipoib/"}]},{"title":"Alpine Linux에서 Timezone 세팅","slug":"alpine-linux-timezone","date":"2018-07-13T01:57:10.000Z","updated":"2018-07-13T01:59:01.432Z","comments":true,"path":"2018/07/13/alpine-linux-timezone/","link":"","permalink":"https://sacoku.github.io/2018/07/13/alpine-linux-timezone/","excerpt":"","text":"Docker로 Image를 만들다 보면, Alpine Linux Base로 할 경우가 많은데, 로그 생성 시, Timezone 문제로 로깅에 어려움을 겪는 경우가 있다. 이 경우 아래의 명령으로 Timezone 문제로 해결 할 수 있다. 12$ apk add tzdata$ cp /usr/share/zoneinfo/Asia/Seoul /etc/localtime","categories":[{"name":"DevOps","slug":"devops","permalink":"https://sacoku.github.io/categories/devops/"},{"name":"Linux","slug":"devops/linux","permalink":"https://sacoku.github.io/categories/devops/linux/"}],"tags":[{"name":"Docker","slug":"docker","permalink":"https://sacoku.github.io/tags/docker/"},{"name":"Alpine Linux","slug":"alpine-linux","permalink":"https://sacoku.github.io/tags/alpine-linux/"},{"name":"Timezone","slug":"timezone","permalink":"https://sacoku.github.io/tags/timezone/"}]},{"title":"GIT CRLF 문제","slug":"git-crlf","date":"2018-07-12T23:42:05.000Z","updated":"2018-10-15T00:41:39.744Z","comments":true,"path":"2018/07/13/git-crlf/","link":"","permalink":"https://sacoku.github.io/2018/07/13/git-crlf/","excerpt":"","text":"Git을 사용하다 보면, Client 환경이 Windows/Linux 등 다른 환경일 경우가 있다.이 경우 서로 다른 line ending으로 인해서 수정이 되지 않았음에도 수정된 것으로 인식하여 협업 시 어려움이 발생하는 경우가 있다.이러한 문제를 해결하기 위해서는 git의 아래의 설정이 필요하다.12$ git config --global core.autocrlf input$ git config --global core.eol lf core.autocrlf options value false 기본설정. 파일에 CRLF 를 썼든 LF 를 썼든 git 은 상관하지 않고 파일 그대로 checkin, checkout 한다. 이 설정은 line ending 이 다른 OS 에서는 text file 이 변경되었다고 나오므로 위에서 언급한 여러 가지 문제가 발생할 수 있다 true text file을 object database 에 넣기전에 CRLF 를 LF 로 변경한다 input LF를 line ending 으로 사용한다. core.eol options value native 기본 설정. 시스템에서 line ending 을 처리하는 방법에 따른다. windows에서는 CRLF 를 사용하고 Linux, OS X 는 LF 만 사용한다. crlf CRLF 를 line ending 으로 사용한다. lf LF를 line ending 으로 사용한다.","categories":[{"name":"DevOps","slug":"devops","permalink":"https://sacoku.github.io/categories/devops/"},{"name":"Git","slug":"devops/git","permalink":"https://sacoku.github.io/categories/devops/git/"}],"tags":[{"name":"Git","slug":"git","permalink":"https://sacoku.github.io/tags/git/"}]},{"title":"2018-07-12","slug":"2018-07-12","date":"2018-07-12T07:49:27.000Z","updated":"2018-07-13T01:23:05.356Z","comments":true,"path":"2018/07/12/2018-07-12/","link":"","permalink":"https://sacoku.github.io/2018/07/12/2018-07-12/","excerpt":"","text":"처음으로 Blog용 페이지 만듬","categories":[{"name":"Blog","slug":"blog","permalink":"https://sacoku.github.io/categories/blog/"},{"name":"2018","slug":"blog/2018","permalink":"https://sacoku.github.io/categories/blog/2018/"}],"tags":[{"name":"Sons","slug":"sons","permalink":"https://sacoku.github.io/tags/sons/"}]},{"title":"Docker Build & Run","slug":"docker-build-run","date":"2018-07-12T07:24:21.000Z","updated":"2018-07-13T01:22:45.874Z","comments":true,"path":"2018/07/12/docker-build-run/","link":"","permalink":"https://sacoku.github.io/2018/07/12/docker-build-run/","excerpt":"","text":"Docker로 Image를 생성해서 Docker-compose로 실행하는 방법에 대해서 서술해보자 한다. Docker Build Image 만들기아래는 Dockerfile 의 기본적인 작성 예이다.12345678910111213141516171819202122232425262728293031323334353637FROM openjdk:8u171-jdk-alpine3.7 #Base ImageMAINTAINER Sunghyun Kim(sacoku@metabuild.co.kr)## Environment VariableENV KRF_HOME=/usr/local/apache-karafENV KFA_HOME=/usr/local/kafka## Apk UpdateRUN apk --update upgrade &amp;&amp; \\ apk --update add sudo bash jq curl &amp;&amp; \\ rm -rf /var/cache/apk/*## karaf installRUN wget http://apache.tt.co.kr/karaf/4.2.0/apache-karaf-4.2.0.tar.gz &amp;&amp; \\ tar xvzf apache-karaf-4.2.0.tar.gz &amp;&amp; \\ mv apache-karaf-4.2.0 /usr/local &amp;&amp; \\ mkdir -p /usr/local/apache-karaf-4.2.0/config/radar &amp;&amp; \\ mkdir -p /usr/local/apache-karaf-4.2.0/config/vsl &amp;&amp; \\ rm apache-karaf-4.2.0.tar.gz &amp;&amp; \\ ln -s /usr/local/apache-karaf-4.2.0 /usr/local/apache-karaf## kafka installRUN wget http://apache.tt.co.kr/kafka/1.1.0/kafka_2.12-1.1.0.tgz &amp;&amp; \\ tar xvzf kafka_2.12-1.1.0.tgz &amp;&amp; \\ mv kafka_2.12-1.1.0 /usr/local &amp;&amp; \\ rm kafka_2.12-1.1.0.tgz &amp;&amp; \\ ln -s /usr/local/kafka_2.12-1.1.0 /usr/local/kafkaCOPY configs/bundle/* $KRF_HOME/deploy/COPY configs/config/radar $KRF_HOME/config/radarCOPY configs/config/vsl $KRF_HOME/config/vslCOPY configs/karaf.sh /rootCOPY configs/kafka.sh /rootCMD [ \"sh\", \"-c\", \"/root/karaf.sh start; /root/kafka.sh start\" ]EXPOSE 1099 8101 44444 8181 Docker build1$ docker build -it metabuild/vsls-karaf . Docker Compose 스크립트아래는 docker-compose.yml 파일의 container 간 Link를 사용하는 기본적인 사용 예이다. 12345678910111213141516171819202122232425262728293031version: \"3\"services: vsls-server: image: metabuild/vsls-karaf container_name: vsls-karaf hostname: vsls-server networks: - vsls-net ports: - 2181:2181 - 9092:9092 - 8181:8181 - 6500:6500 environment: ADVERTISED_HOST: vsls-server ADVERTISED_PORT: 9092 vsls-web: image: metabuild/vsls-web container_name: vsls-web ports: - 81:81 - 8082:8082 - 9000:9000 links: - vsls-server # vsls-server와 link되어서 networks: vsls-net: driver: bridge Docker 실행1$ docker-compose up -d","categories":[{"name":"DevOps","slug":"devops","permalink":"https://sacoku.github.io/categories/devops/"},{"name":"Docker","slug":"devops/docker","permalink":"https://sacoku.github.io/categories/devops/docker/"}],"tags":[{"name":"Docker","slug":"docker","permalink":"https://sacoku.github.io/tags/docker/"}]},{"title":"Docker Summary","slug":"docker-summary","date":"2018-07-12T03:37:37.000Z","updated":"2018-07-13T00:30:13.472Z","comments":true,"path":"2018/07/12/docker-summary/","link":"","permalink":"https://sacoku.github.io/2018/07/12/docker-summary/","excerpt":"","text":"Dockerfile buildDockerfile이 있는 디렉토리에서 아래의 명령어를 실행 1$ docker build -t [tag] . Docker 실행 1$ docker run -p 8080:8081 -p 1234:1111 -v /var/tmp:/data [image name] Docker container List 확인 1$ docker ps -a Docker image List 확인 1$ docker images Docker image 삭제 1$ docker rmi [image id] Docker Container 삭제 1$ docker rm [Container ID] Docker Container Start/Stop 1$ docker start/stop [Container ID] Docker Volume 생성 &amp; 실행 12$ docker volume create --name data$ docker run --name=test -p 10022:22 -v data:/data [image] Docker Container 명령어 싫행 1$ docker exec -it [Container ID] [Command] Container를 Image로 만들기 123$ docker commit [options] &lt;container name&gt; [image name[:tag name]]# example$ docker commit -a &quot;catchup&quot; -m &quot;www.leafcats.com&quot; nginx_base catchup/myapp Option Description - a, –author=”” 생성자 정보 -m, –message=”” 이미지 메시지 -p, –pause=true/false 이미지를 생성할 때 컨테이너를 중지(stop) 한 뒤 commit 여부 Docker Image import/export1234# export$ docker save image_name &gt; ./backup.tar# import$ docker load -i ./backup.tar Docker Container import/export1234# export$ docker export [container_name] &gt; ./backup.tar# import$ docker import ./backup.tar","categories":[{"name":"DevOps","slug":"devops","permalink":"https://sacoku.github.io/categories/devops/"},{"name":"Docker","slug":"devops/docker","permalink":"https://sacoku.github.io/categories/devops/docker/"}],"tags":[{"name":"Docker","slug":"docker","permalink":"https://sacoku.github.io/tags/docker/"}]},{"title":"How to Hadoop HDFS NFS","slug":"how-to-hadoop-hdfs-nfs","date":"2018-07-12T00:07:49.000Z","updated":"2018-07-13T01:21:52.876Z","comments":true,"path":"2018/07/12/how-to-hadoop-hdfs-nfs/","link":"","permalink":"https://sacoku.github.io/2018/07/12/how-to-hadoop-hdfs-nfs/","excerpt":"","text":"Apache Hadoop은 NFS Gateway를 지원 해준다. 근데, 공식 문서에서는 exports point를 직접 지정 하는 방법은 나와있지 않다. 1. hdfs-site.xml nfs 옵션 추가이 값은 hadoop 2.5.x 버전 이상에서만 존재함 1$ nano $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;&lt;configuration&gt;................................................................................................................................. &lt;!-- NFS v3 --&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;nfs.exports.allowed.hosts&lt;/name&gt; &lt;value&gt;* rw&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;nfs.export.point&lt;/name&gt; &lt;value&gt;/ruo91&lt;/value&gt; &lt;!-- HDFS상에 실제 존재해야 하는 디렉토리여야 함 --&gt; &lt;/property&gt;&lt;/configuration&gt; Property Description hadoop.proxyuser.[userid].groups NFS를 마운트를 허용할 사용자 hadoop.proxyuser.[userid].hosts 이 옵션에 값을 *로 설정하면 모든 호스트들에게 NFS Gateway 허용 nfs.exports.allowed.hosts NFS Client가 Mount시 허용할 Host와 권한을 지정할때 사용한다. nfs.export.point NFS의 exports point를 직접 지정할 수 있는 부분이다. 2. Data Node 재시작1$ stop-dfs.sh all &amp;&amp; start-dfs.sh 3. Hadoop NFS GatewayHostOS에 기존에 동작하고 있던 portmap, nfs 서비스를 사전에 모두 중지 해야한다.(물론 사용하는 OS에 따라 서비스 중지법은 다르다.)1$ service nfs stop &amp;&amp; service rpcbind Hadoop의 Portmap, NFS 서버를 실행하는 방법은 2가지가 있다.첫번째는 hadoop-daemon.sh 스크립트를 사용하여 background에서 실행하는 방법.두번째는 hdfs 명령어를 통해 foreground에서 실행하는 방법이 있다. 본인은 정상 Mount 되었는지 확인 하기 위해서 두번째 방법으로 실행 하겠다.12$ hdfs portmap &amp;$ hdfs nfs3 &amp; 4. Test정상적으로 Mount 되었는지 확인하기 위해 HDFS에 디렉토리를 만들고, 임의로 생성한 파일을 복사하여 NFS Client에서 Mount 해볼 것이다. 로그 생성 및 복사12345678$ hdfs dfs -mkdir -p /ruo91/logs$ for((i=0; i&lt;10; i++)) do echo $&#123;i&#125;; done &gt; /tmp/test.log$ hdfs dfs -copyFromLocal /tmp/test.log /ruo91/logs/test.log$ hdfs dfs -ls -R /ruo91drwxr-xr-x - root supergroup 0 2015-02-11 23:35 /ruo91/logs-rw-r--r-- 1 root supergroup 20 2015-02-11 23:35 /ruo91/logs/test.log-rw-r--r-- 1 root supergroup 1160435178 2015-02-11 22:24 /ruo91/logs/yongbok.net-access-logs.json NFS Client Mount 테스트exports point 확인 123$ showmount -eExport list for ruo91:/ruo91 * 디렉토리 생성 및 mount 12$ mkdir /hdfs-nfs3$ mount -t nfs -o vers=3,proto=tcp,nolock localhost:/ruo91 /hdfs-nfs3 mount 디렉토리 확인 123456789101112131415161718$ mount | grep hdfslocalhost:/ruo91 on /hdfs-nfs3 type nfs (rw,vers=3,proto=tcp,nolock,addr=127.0.0.1)$ ls -alR /hdfs-nfs3 root@ruo91:~# ls -alR /hdfs-nfs3/hdfs-nfs3:total 5drwxr-xr-x 3 root 2584148964 96 2월 11 22:23 .drwxr-xr-x 27 root root 4096 2월 11 22:22 ..drwxr-xr-x 4 root 2584148964 128 2월 11 23:35 logs/hdfs-nfs3/logs:total 1133239drwxr-xr-x 4 root 2584148964 128 2월 11 23:35 .drwxr-xr-x 3 root 2584148964 96 2월 11 22:23 ..-rw-r--r-- 1 root 2584148964 20 2월 11 23:35 test.log-rw-r--r-- 1 root 2584148964 1160435178 2월 11 22:24 yongbok.net-access-logs.json 위와 같이 정상적으로 마운트가 되면 Hadoop NFS 서버에는 아래와 같은 INFO 메세지가 나오면 잘 된거다.115/02/11 23:42:16 INFO mount.RpcProgramMountd: Giving handle (fileId:16386) to client for export /ruo91 윈도우에서 접근시 12345678910111213$ mount -o anon \\\\10.1.2.221\\user\\root\\data Z:명령을 완료했습니다.$ mount로컬 원격 속성-------------------------------------------------------------------------------r: \\\\10.1.2.221\\user\\root\\data UID=0, GID=0 rsize=1048576, wsize=1048576 mount=soft, timeout=0.8 retry=1, locking=no fileaccess=755, lang=KSC5601 casesensitive=no sec=sys anon:anonymouns default uid/gid가 -2로 설정 되어 있기 때문에 변경이 필요하다.변경은 “HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\ClientForNFS\\CurrentVersion\\Default”에 아래의 값을 설정해야 한다. Name Type Data AnonymounsUid REG_DWORD 0x00000000(0) AnonymounsGid REG_DWORD 0x00000000(0)","categories":[{"name":"Bigdata","slug":"bigdata","permalink":"https://sacoku.github.io/categories/bigdata/"},{"name":"Hadoop","slug":"bigdata/hadoop","permalink":"https://sacoku.github.io/categories/bigdata/hadoop/"}],"tags":[{"name":"Bigdata","slug":"bigdata","permalink":"https://sacoku.github.io/tags/bigdata/"},{"name":"Hadoop","slug":"hadoop","permalink":"https://sacoku.github.io/tags/hadoop/"}]}]}