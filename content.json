{"meta":{"title":"sacoku's github.io","subtitle":"Develop History","description":null,"author":"sacoku","url":"https://sacoku.github.io"},"pages":[{"title":"","date":"2018-07-12T00:28:18.726Z","updated":"2018-07-12T00:28:18.726Z","comments":true,"path":"404/index.html","permalink":"https://sacoku.github.io/404/index.html","excerpt":"","text":""},{"title":"","date":"2018-07-12T00:26:17.021Z","updated":"2018-07-12T00:26:17.022Z","comments":true,"path":"about/index.html","permalink":"https://sacoku.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"GIT CRLF 문제","slug":"git-crlf","date":"2018-07-12T23:42:05.000Z","updated":"2018-07-13T01:02:21.845Z","comments":true,"path":"2018/07/13/git-crlf/","link":"","permalink":"https://sacoku.github.io/2018/07/13/git-crlf/","excerpt":"","text":"Git을 사용하다 보면, Client 환경이 Windows/Linux 등 다른 환경일 경우가 있다.이 경우 서로 다른 line ending으로 인해서 수정이 되지 않았음에도 수정된 것으로 인식하여 협업 시 어려움이 발생하는 경우가 있다.이러한 문제를 해결하기 위해서는 git의 아래의 설정이 필요하다.12$ git config --global core.autocrlf input$ git config --global core.eol lf core.autocrlf options value false 기본설정. 파일에 CRLF 를 썼든 LF 를 썼든 git 은 상관하지 않고 파일 그대로 checkin, checkout 한다. 이 설정은 line ending 이 다른 OS 에서는 text file 이 변경되었다고 나오므로 위에서 언급한 여러 가지 문제가 발생할 수 있다 true text file을 object database 에 넣기전에 CRLF 를 LF 로 변경한다 input LF를 line ending 으로 사용한다. core.eol options value native 기본 설정. 시스템에서 line ending 을 처리하는 방법에 따른다. windows에서는 CRLF 를 사용하고 Linux, OS X 는 LF 만 사용한다. crlf CRLF 를 line ending 으로 사용한다. lf LF를 line ending 으로 사용한다.","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://sacoku.github.io/categories/DevOps/"},{"name":"Docker","slug":"DevOps/Docker","permalink":"https://sacoku.github.io/categories/DevOps/Docker/"},{"name":"Git","slug":"DevOps/Git","permalink":"https://sacoku.github.io/categories/DevOps/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://sacoku.github.io/tags/Git/"}]},{"title":"2018-07-12","slug":"2018-07-12","date":"2018-07-12T07:49:27.000Z","updated":"2018-07-12T07:53:40.989Z","comments":true,"path":"2018/07/12/2018-07-12/","link":"","permalink":"https://sacoku.github.io/2018/07/12/2018-07-12/","excerpt":"","text":"처음으로 Blog용 페이지 만듬","categories":[{"name":"Blog","slug":"Blog","permalink":"https://sacoku.github.io/categories/Blog/"}],"tags":[{"name":"Sons","slug":"Sons","permalink":"https://sacoku.github.io/tags/Sons/"}]},{"title":"Docker Build & Run","slug":"docker-build-run","date":"2018-07-12T07:24:21.000Z","updated":"2018-07-13T00:42:14.270Z","comments":true,"path":"2018/07/12/docker-build-run/","link":"","permalink":"https://sacoku.github.io/2018/07/12/docker-build-run/","excerpt":"","text":"Docker로 Image를 생성해서 Docker-compose로 실행하는 방법에 대해서 서술해보자 한다. Docker Build Image 만들기아래는 Dockerfile 의 기본적인 작성 예이다.12345678910111213141516171819202122232425262728293031323334353637FROM openjdk:8u171-jdk-alpine3.7 #Base ImageMAINTAINER Sunghyun Kim(sacoku@metabuild.co.kr)## Environment VariableENV KRF_HOME=/usr/local/apache-karafENV KFA_HOME=/usr/local/kafka## Apk UpdateRUN apk --update upgrade &amp;&amp; \\ apk --update add sudo bash jq curl &amp;&amp; \\ rm -rf /var/cache/apk/*## karaf installRUN wget http://apache.tt.co.kr/karaf/4.2.0/apache-karaf-4.2.0.tar.gz &amp;&amp; \\ tar xvzf apache-karaf-4.2.0.tar.gz &amp;&amp; \\ mv apache-karaf-4.2.0 /usr/local &amp;&amp; \\ mkdir -p /usr/local/apache-karaf-4.2.0/config/radar &amp;&amp; \\ mkdir -p /usr/local/apache-karaf-4.2.0/config/vsl &amp;&amp; \\ rm apache-karaf-4.2.0.tar.gz &amp;&amp; \\ ln -s /usr/local/apache-karaf-4.2.0 /usr/local/apache-karaf## kafka installRUN wget http://apache.tt.co.kr/kafka/1.1.0/kafka_2.12-1.1.0.tgz &amp;&amp; \\ tar xvzf kafka_2.12-1.1.0.tgz &amp;&amp; \\ mv kafka_2.12-1.1.0 /usr/local &amp;&amp; \\ rm kafka_2.12-1.1.0.tgz &amp;&amp; \\ ln -s /usr/local/kafka_2.12-1.1.0 /usr/local/kafkaCOPY configs/bundle/* $KRF_HOME/deploy/COPY configs/config/radar $KRF_HOME/config/radarCOPY configs/config/vsl $KRF_HOME/config/vslCOPY configs/karaf.sh /rootCOPY configs/kafka.sh /rootCMD [ \"sh\", \"-c\", \"/root/karaf.sh start; /root/kafka.sh start\" ]EXPOSE 1099 8101 44444 8181 Docker build1$ docker build -it metabuild/vsls-karaf . Docker Compose 스크립트아래는 docker-compose.yml 파일의 container 간 Link를 사용하는 기본적인 사용 예이다. 12345678910111213141516171819202122232425262728293031version: \"3\"services: vsls-server: image: metabuild/vsls-karaf container_name: vsls-karaf hostname: vsls-server networks: - vsls-net ports: - 2181:2181 - 9092:9092 - 8181:8181 - 6500:6500 environment: ADVERTISED_HOST: vsls-server ADVERTISED_PORT: 9092 vsls-web: image: metabuild/vsls-web container_name: vsls-web ports: - 81:81 - 8082:8082 - 9000:9000 links: - vsls-server # vsls-server와 link되어서 networks: vsls-net: driver: bridge Docker 실행1$ docker-compose up -d","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://sacoku.github.io/categories/DevOps/"},{"name":"Docker","slug":"DevOps/Docker","permalink":"https://sacoku.github.io/categories/DevOps/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://sacoku.github.io/tags/Docker/"}]},{"title":"Docker Summary","slug":"docker-summary","date":"2018-07-12T03:37:37.000Z","updated":"2018-07-13T00:30:13.472Z","comments":true,"path":"2018/07/12/docker-summary/","link":"","permalink":"https://sacoku.github.io/2018/07/12/docker-summary/","excerpt":"","text":"Dockerfile buildDockerfile이 있는 디렉토리에서 아래의 명령어를 실행 1$ docker build -t [tag] . Docker 실행 1$ docker run -p 8080:8081 -p 1234:1111 -v /var/tmp:/data [image name] Docker container List 확인 1$ docker ps -a Docker image List 확인 1$ docker images Docker image 삭제 1$ docker rmi [image id] Docker Container 삭제 1$ docker rm [Container ID] Docker Container Start/Stop 1$ docker start/stop [Container ID] Docker Volume 생성 &amp; 실행 12$ docker volume create --name data$ docker run --name=test -p 10022:22 -v data:/data [image] Docker Container 명령어 싫행 1$ docker exec -it [Container ID] [Command] Container를 Image로 만들기 123$ docker commit [options] &lt;container name&gt; [image name[:tag name]]# example$ docker commit -a &quot;catchup&quot; -m &quot;www.leafcats.com&quot; nginx_base catchup/myapp Option Description - a, –author=”” 생성자 정보 -m, –message=”” 이미지 메시지 -p, –pause=true/false 이미지를 생성할 때 컨테이너를 중지(stop) 한 뒤 commit 여부 Docker Image import/export1234# export$ docker save image_name &gt; ./backup.tar# import$ docker load -i ./backup.tar Docker Container import/export1234# export$ docker export [container_name] &gt; ./backup.tar# import$ docker import ./backup.tar","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://sacoku.github.io/categories/DevOps/"},{"name":"Docker","slug":"DevOps/Docker","permalink":"https://sacoku.github.io/categories/DevOps/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://sacoku.github.io/tags/Docker/"}]},{"title":"How to Hadoop HDFS NFS","slug":"how-to-hadoop-hdfs-nfs","date":"2018-07-12T00:07:49.000Z","updated":"2018-07-13T00:34:20.990Z","comments":true,"path":"2018/07/12/how-to-hadoop-hdfs-nfs/","link":"","permalink":"https://sacoku.github.io/2018/07/12/how-to-hadoop-hdfs-nfs/","excerpt":"","text":"Apache Hadoop은 NFS Gateway를 지원 해준다. 근데, 공식 문서에서는 exports point를 직접 지정 하는 방법은 나와있지 않다. 1. hdfs-site.xml nfs 옵션 추가이 값은 hadoop 2.5.x 버전 이상에서만 존재함 1$ nano $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;&lt;configuration&gt;................................................................................................................................. &lt;!-- NFS v3 --&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;nfs.exports.allowed.hosts&lt;/name&gt; &lt;value&gt;* rw&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;nfs.export.point&lt;/name&gt; &lt;value&gt;/ruo91&lt;/value&gt; &lt;!-- HDFS상에 실제 존재해야 하는 디렉토리여야 함 --&gt; &lt;/property&gt;&lt;/configuration&gt; Property Description hadoop.proxyuser.[userid].groups NFS를 마운트를 허용할 사용자 hadoop.proxyuser.[userid].hosts 이 옵션에 값을 *로 설정하면 모든 호스트들에게 NFS Gateway 허용 nfs.exports.allowed.hosts NFS Client가 Mount시 허용할 Host와 권한을 지정할때 사용한다. nfs.export.point NFS의 exports point를 직접 지정할 수 있는 부분이다. 2. Data Node 재시작1$ stop-dfs.sh all &amp;&amp; start-dfs.sh 3. Hadoop NFS GatewayHostOS에 기존에 동작하고 있던 portmap, nfs 서비스를 사전에 모두 중지 해야한다.(물론 사용하는 OS에 따라 서비스 중지법은 다르다.)1$ service nfs stop &amp;&amp; service rpcbind Hadoop의 Portmap, NFS 서버를 실행하는 방법은 2가지가 있다.첫번째는 hadoop-daemon.sh 스크립트를 사용하여 background에서 실행하는 방법.두번째는 hdfs 명령어를 통해 foreground에서 실행하는 방법이 있다. 본인은 정상 Mount 되었는지 확인 하기 위해서 두번째 방법으로 실행 하겠다.12$ hdfs portmap &amp;$ hdfs nfs3 &amp; 4. Test정상적으로 Mount 되었는지 확인하기 위해 HDFS에 디렉토리를 만들고, 임의로 생성한 파일을 복사하여 NFS Client에서 Mount 해볼 것이다. 로그 생성 및 복사12345678$ hdfs dfs -mkdir -p /ruo91/logs$ for((i=0; i&lt;10; i++)) do echo $&#123;i&#125;; done &gt; /tmp/test.log$ hdfs dfs -copyFromLocal /tmp/test.log /ruo91/logs/test.log$ hdfs dfs -ls -R /ruo91drwxr-xr-x - root supergroup 0 2015-02-11 23:35 /ruo91/logs-rw-r--r-- 1 root supergroup 20 2015-02-11 23:35 /ruo91/logs/test.log-rw-r--r-- 1 root supergroup 1160435178 2015-02-11 22:24 /ruo91/logs/yongbok.net-access-logs.json NFS Client Mount 테스트exports point 확인 123$ showmount -eExport list for ruo91:/ruo91 * 디렉토리 생성 및 mount 12$ mkdir /hdfs-nfs3$ mount -t nfs -o vers=3,proto=tcp,nolock localhost:/ruo91 /hdfs-nfs3 mount 디렉토리 확인 123456789101112131415161718$ mount | grep hdfslocalhost:/ruo91 on /hdfs-nfs3 type nfs (rw,vers=3,proto=tcp,nolock,addr=127.0.0.1)$ ls -alR /hdfs-nfs3 root@ruo91:~# ls -alR /hdfs-nfs3/hdfs-nfs3:total 5drwxr-xr-x 3 root 2584148964 96 2월 11 22:23 .drwxr-xr-x 27 root root 4096 2월 11 22:22 ..drwxr-xr-x 4 root 2584148964 128 2월 11 23:35 logs/hdfs-nfs3/logs:total 1133239drwxr-xr-x 4 root 2584148964 128 2월 11 23:35 .drwxr-xr-x 3 root 2584148964 96 2월 11 22:23 ..-rw-r--r-- 1 root 2584148964 20 2월 11 23:35 test.log-rw-r--r-- 1 root 2584148964 1160435178 2월 11 22:24 yongbok.net-access-logs.json 위와 같이 정상적으로 마운트가 되면 Hadoop NFS 서버에는 아래와 같은 INFO 메세지가 나오면 잘 된거다.115/02/11 23:42:16 INFO mount.RpcProgramMountd: Giving handle (fileId:16386) to client for export /ruo91 윈도우에서 접근시 12345678910111213$ mount -o anon \\\\10.1.2.221\\user\\root\\data Z:명령을 완료했습니다.$ mount로컬 원격 속성-------------------------------------------------------------------------------r: \\\\10.1.2.221\\user\\root\\data UID=0, GID=0 rsize=1048576, wsize=1048576 mount=soft, timeout=0.8 retry=1, locking=no fileaccess=755, lang=KSC5601 casesensitive=no sec=sys anon:anonymouns default uid/gid가 -2로 설정 되어 있기 때문에 변경이 필요하다.변경은 “HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\ClientForNFS\\CurrentVersion\\Default”에 아래의 값을 설정해야 한다. Name Type Data AnonymounsUid REG_DWORD 0x00000000(0) AnonymounsGid REG_DWORD 0x00000000(0)","categories":[{"name":"Bigdata","slug":"Bigdata","permalink":"https://sacoku.github.io/categories/Bigdata/"},{"name":"Hadoop","slug":"Bigdata/Hadoop","permalink":"https://sacoku.github.io/categories/Bigdata/Hadoop/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://sacoku.github.io/tags/Hadoop/"}]}]}